{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9978d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, Sequential, MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "import numpy as np\n",
    "from torch_geometric.data import Batch\n",
    "import torch\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "DEVICE = torch.device(\"cuda:0\" if not torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acca299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contains non-linear activation function ReLu.\n",
    "    This likely wont be an effective approximation for the data.\n",
    "    You could experiment with sigmoid, or preferably,\n",
    "    you could try using a non-linear layer such as:\n",
    "        - a multi-layer perceptron (MLP)\n",
    "        - RNN with\n",
    "            - a gated recurrent unit (GRU)\n",
    "            - long short-term memory (LSTM) unit\n",
    "        - RNN layer can add significant performance see:\n",
    "            https://ieeexplore.ieee.org/document/9649108\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TemporalLayer, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Sort the edges by timestamp to ensure the correct temporal order\n",
    "        #edge_attr, perm = edge_attr.sort()\n",
    "        #edge_index = edge_index[:, perm]\n",
    "        #x = x[perm]\n",
    "\n",
    "        # Aggregate the temporal information for each node using the mean\n",
    "        node_attrs = torch.zeros(x.shape[0], edge_attr.shape[1], device=x.device)\n",
    "        node_attrs.index_add_(0, edge_index[1], edge_attr)\n",
    "        node_counts = torch.zeros(x.shape[0], edge_attr.shape[1], device=x.device)\n",
    "        node_counts.index_add_(0, edge_index[1], torch.ones_like(edge_attr))\n",
    "        node_attrs /= node_counts\n",
    "\n",
    "        # Pass the node attributes through a linear layer to get the temporal embeddings\n",
    "        x = F.relu(self.linear(node_attrs))\n",
    "\n",
    "        return x\n",
    "\n",
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.temporal = TemporalLayer(in_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        print(x.shape)\n",
    "        print(x[0])\n",
    "        \n",
    "        batch_size = x.shape[1]\n",
    "        \n",
    "        x = x.reshape(batch_size, -1)\n",
    "        print(x.shape)\n",
    "        #x = self.temporal(x, edge_index, edge_attr)  # Pass through temporal layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b783ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, LR=0.1, epochs=2000, val_loader=None):\n",
    "    net.to(DEVICE)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "    criterion = nn.L1Loss()\n",
    "    all_MSE = nn.L1Loss()\n",
    "    val_losses = []\n",
    "    print(f\"Using: {DEVICE}\")\n",
    "                            \n",
    "    parameter_loss = []\n",
    "    losses = []\n",
    "    processed = 0\n",
    "    last_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        \n",
    "        net.train()\n",
    "        with tqdm(train_loader, unit=\"batch\") as it:\n",
    "            if epoch > 0:\n",
    "                it.set_postfix(lastLoss=last_loss, valLoss=val_losses[-1])\n",
    "            for idx, batch in enumerate(it):\n",
    "                it.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "                batch.to(DEVICE)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch)\n",
    "                loss = loss_fn(out, batch.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                for i in range(len(predicted)):\n",
    "                    current_MSE = []\n",
    "                    for j in range(6):\n",
    "                        current_MSE.append(all_MSE(out[i][j], predicted[i][j]).item())\n",
    "                    parameter_loss.append(current_MSE)\n",
    "                    processed += 1\n",
    "        \n",
    "        if val_loader:\n",
    "            val_loss = 0\n",
    "            net.eval()\n",
    "            for idx, data in enumerate(val_loader):\n",
    "                inp, out = data['input'].to(DEVICE), data['output'].to(DEVICE)\n",
    "\n",
    "                predicted = net(inp)\n",
    "                cost = criterion(out, predicted)\n",
    "                val_loss += cost.item()\n",
    "            val_loss /= len(val_loader)  \n",
    "            val_losses.append(val_loss)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        last_loss = loss/len(it)\n",
    "    print(\"Parameters: Skin YM, Adipose YM, Skin PR, Adipose PR, Skin Perm, Adipose Perm\")\n",
    "    print(f\"Sampled Ranges: 10e3 - 50e3, 1e3 - 25e3, 0.48 - 0.499, 0.48 - 0.499, 10e - 12-10e10, 10e-12 - 10e10\") \n",
    "    print(f\"Average parameter loss: {np.mean(np.reshape(np.array(parameter_loss), (-1, 6)), axis=0)}\")        \n",
    "    print(f\"Average overall loss: {np.sum(losses)/processed}\")\n",
    "    return losses, parameter_loss, val_losses\n",
    "\n",
    "def test(test_loader, net):\n",
    "    net.to(DEVICE)\n",
    "    net.eval()\n",
    "    criterion = nn.L1Loss()\n",
    "    crit = nn.L1Loss()\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "            loss = 0\n",
    "            with tqdm(test_loader, unit=\" batch\") as it:\n",
    "                for batch in enumerate(it):\n",
    "                    loss = loss_fn(out, batch.y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    predicted = net(inp) \n",
    "                    cost = criterion(out, predicted)\n",
    "                    l_t = cost.item()\n",
    "                    loss += l_t\n",
    "                    for i in range(len(predicted)):\n",
    "                        p = predicted[i].cpu().numpy().reshape(1, -1)\n",
    "                        o = out[i].cpu().numpy().reshape(1, -1)\n",
    "                        print(F\"Predicted: {SCALER.inverse_transform(p)}\")\n",
    "                        print(F\"Real: {SCALER.inverse_transform(o)}\")\n",
    "                        print(f\"Difference: {abs(p - o)}\\n\\n\")\n",
    "                    \n",
    "                    #print(f\"\\n\\n\\nBatch: {idx}\")\n",
    "                   # print(f\"loss: {l_t}\")\n",
    "                    #for i, target in enumerate(out):\n",
    "                   #     errs = []\n",
    "                   #     print(f\"Targer: {target}, \\npredicted: {predicted[i]}\\n\\n\")\n",
    "                   #     for j in range(len(predicted)):\n",
    "                   #         errs.append(abs(predicted[i]-target[i])**2)\n",
    "                   #     print(f\"MSE: {np.mean(errs[0])}\")\n",
    "            \n",
    "            print(f\"Average Loss: {loss/len(test_loader)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c933a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[2, 128], edge_index=[16129, 4], y=[6], edge_weight=[4]), Data(x=[2, 128], edge_index=[16129, 4], y=[6], edge_weight=[4])]\n",
      "BATCH:  DataBatch(x=[4, 128], edge_index=[16129, 8], y=[12], edge_weight=[8], batch=[4], ptr=[3])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\data\\storage.py:62\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\data\\storage.py:85\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reshape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36mcustom_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03mCollate function that can handle PyTorch Geometric Data objects.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBATCH: \u001b[39m\u001b[38;5;124m\"\u001b[39m, Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(batch))\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\data\\data.py:428\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\data\\storage.py:64\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9032cf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 202.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.8188e-05,  1.7118e-03,  2.2192e-03,  2.3846e-03,  2.4989e-03,\n",
      "          2.5882e-03,  2.6623e-03,  2.7262e-03,  2.7832e-03,  2.8352e-03,\n",
      "          2.8835e-03,  2.9285e-03,  2.9709e-03,  3.0106e-03,  3.0478e-03,\n",
      "          3.0827e-03,  3.1154e-03,  3.1459e-03,  3.1744e-03,  3.2010e-03,\n",
      "          3.2259e-03,  3.2492e-03,  3.2709e-03,  3.2912e-03,  3.3102e-03,\n",
      "          3.3279e-03,  3.3445e-03,  3.3600e-03,  3.3745e-03,  3.3881e-03,\n",
      "          3.4008e-03,  3.4127e-03,  3.4239e-03,  3.4343e-03,  3.4441e-03,\n",
      "          3.4532e-03,  3.4618e-03,  3.4698e-03,  3.4773e-03,  3.4844e-03,\n",
      "          3.4910e-03,  3.4972e-03,  3.5030e-03,  3.5084e-03,  3.5135e-03,\n",
      "          3.5183e-03,  3.5228e-03,  3.5270e-03,  3.5309e-03,  3.5346e-03,\n",
      "          3.5381e-03,  3.5413e-03,  3.5444e-03,  3.5473e-03,  3.5499e-03,\n",
      "          3.5525e-03,  3.5548e-03,  3.5570e-03,  3.5591e-03,  3.5611e-03,\n",
      "          3.5629e-03,  3.5646e-03,  3.5662e-03,  3.5677e-03,  3.5691e-03,\n",
      "          3.5705e-03,  3.5717e-03,  3.5729e-03,  3.5740e-03,  3.5750e-03,\n",
      "          3.5760e-03,  3.5769e-03,  3.5777e-03,  3.5785e-03,  3.5793e-03,\n",
      "          3.5800e-03,  3.5807e-03,  3.5813e-03,  3.5819e-03,  3.5824e-03,\n",
      "          3.5829e-03,  3.5834e-03,  3.5838e-03,  3.5843e-03,  3.5847e-03,\n",
      "          3.5850e-03,  3.5854e-03,  3.5857e-03,  3.5860e-03,  3.5863e-03,\n",
      "          3.5866e-03,  3.5865e-03,  2.7328e-03,  1.0021e-03,  9.9419e-06,\n",
      "         -4.9297e-05, -5.2905e-05, -5.3250e-05, -5.3315e-05, -5.3337e-05,\n",
      "         -5.3347e-05, -5.3351e-05, -5.3354e-05, -5.3355e-05, -5.3356e-05,\n",
      "         -5.3356e-05, -5.3356e-05, -5.3356e-05, -5.3356e-05, -5.3356e-05,\n",
      "         -5.3356e-05, -5.3356e-05, -5.3356e-05, -5.3356e-05, -5.3356e-05,\n",
      "         -5.3356e-05, -5.3356e-05, -5.3356e-05, -5.3356e-05, -5.3356e-05,\n",
      "         -5.3356e-05, -5.3356e-05, -5.3356e-05, -5.3356e-05, -5.3356e-05,\n",
      "         -5.3356e-05, -5.3356e-05, -5.3356e-05],\n",
      "        [-4.1360e-07,  1.0420e-04,  1.2449e-03,  2.6649e-03,  3.9387e-03,\n",
      "          5.0197e-03,  5.9315e-03,  6.7062e-03,  7.3707e-03,  7.9458e-03,\n",
      "          8.4475e-03,  8.8881e-03,  9.2772e-03,  9.6228e-03,  9.9310e-03,\n",
      "          1.0207e-02,  1.0456e-02,  1.0681e-02,  1.0884e-02,  1.1070e-02,\n",
      "          1.1240e-02,  1.1396e-02,  1.1540e-02,  1.1673e-02,  1.1796e-02,\n",
      "          1.1911e-02,  1.2018e-02,  1.2119e-02,  1.2213e-02,  1.2303e-02,\n",
      "          1.2387e-02,  1.2468e-02,  1.2545e-02,  1.2618e-02,  1.2689e-02,\n",
      "          1.2757e-02,  1.2823e-02,  1.2886e-02,  1.2948e-02,  1.3008e-02,\n",
      "          1.3066e-02,  1.3123e-02,  1.3179e-02,  1.3233e-02,  1.3286e-02,\n",
      "          1.3339e-02,  1.3390e-02,  1.3441e-02,  1.3490e-02,  1.3539e-02,\n",
      "          1.3588e-02,  1.3635e-02,  1.3682e-02,  1.3728e-02,  1.3774e-02,\n",
      "          1.3819e-02,  1.3864e-02,  1.3908e-02,  1.3952e-02,  1.3996e-02,\n",
      "          1.4039e-02,  1.4081e-02,  1.4124e-02,  1.4165e-02,  1.4207e-02,\n",
      "          1.4248e-02,  1.4289e-02,  1.4330e-02,  1.4370e-02,  1.4410e-02,\n",
      "          1.4449e-02,  1.4489e-02,  1.4528e-02,  1.4567e-02,  1.4605e-02,\n",
      "          1.4643e-02,  1.4682e-02,  1.4719e-02,  1.4757e-02,  1.4794e-02,\n",
      "          1.4831e-02,  1.4868e-02,  1.4905e-02,  1.4941e-02,  1.4977e-02,\n",
      "          1.5013e-02,  1.5049e-02,  1.5084e-02,  1.5119e-02,  1.5154e-02,\n",
      "          1.5189e-02,  1.5224e-02,  1.5123e-02,  1.3497e-02,  1.1680e-02,\n",
      "          1.0233e-02,  9.0400e-03,  8.0309e-03,  7.1616e-03,  6.3997e-03,\n",
      "          5.7198e-03,  5.1015e-03,  4.5275e-03,  3.9829e-03,  3.4560e-03,\n",
      "          2.9383e-03,  2.4226e-03,  1.8995e-03,  1.3797e-03,  9.9318e-04,\n",
      "          7.1717e-04,  5.1850e-04,  3.7464e-04,  2.7032e-04,  1.9480e-04,\n",
      "          1.4028e-04,  1.0100e-04,  7.2750e-05,  5.2465e-05,  3.7913e-05,\n",
      "          2.7480e-05,  2.0004e-05,  1.4649e-05,  1.0815e-05,  8.0696e-06,\n",
      "          6.1044e-06,  4.6978e-06,  3.6910e-06]])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the dataset\n",
    "dataset = SignalDataset(runs=runs[:10])\n",
    "\n",
    "train_n = int(0.8 * len(dataset))\n",
    "test_n = len(dataset) - train_n\n",
    "train_set, test_set = random_split(dataset, [train_n, test_n])\n",
    "train_loader, test_loader = DataLoader(train_set, batch_size=2, shuffle=True, collate_fn=custom_collate), \\\n",
    "                            DataLoader(test_set, batch_size=2, shuffle=True, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "533eb1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16129"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "297db007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000:   0%|                                                                           | 0/4 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[2, 128], edge_index=[16129, 4], y=[6], edge_weight=[4]), Data(x=[2, 128], edge_index=[16129, 4], y=[6], edge_weight=[4])]\n",
      "BATCH:  DataBatch(x=[4, 128], edge_index=[16129, 8], y=[12], edge_weight=[8], batch=[4], ptr=[3])\n",
      "torch.Size([4, 128])\n",
      "tensor([-1.1091e-05,  6.4674e-04,  1.2096e-03,  1.4585e-03,  1.5985e-03,\n",
      "         1.6890e-03,  1.7529e-03,  1.8004e-03,  1.8370e-03,  1.8659e-03,\n",
      "         1.8891e-03,  1.9078e-03,  1.9232e-03,  1.9358e-03,  1.9463e-03,\n",
      "         1.9550e-03,  1.9623e-03,  1.9684e-03,  1.9736e-03,  1.9779e-03,\n",
      "         1.9816e-03,  1.9847e-03,  1.9873e-03,  1.9895e-03,  1.9914e-03,\n",
      "         1.9930e-03,  1.9944e-03,  1.9956e-03,  1.9966e-03,  1.9974e-03,\n",
      "         1.9982e-03,  1.9988e-03,  1.9993e-03,  1.9998e-03,  2.0002e-03,\n",
      "         2.0005e-03,  2.0008e-03,  2.0010e-03,  2.0013e-03,  2.0014e-03,\n",
      "         2.0016e-03,  2.0017e-03,  2.0018e-03,  2.0019e-03,  2.0020e-03,\n",
      "         2.0021e-03,  2.0022e-03,  2.0022e-03,  2.0023e-03,  2.0023e-03,\n",
      "         2.0023e-03,  2.0024e-03,  2.0024e-03,  2.0024e-03,  2.0024e-03,\n",
      "         2.0024e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,\n",
      "         2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,\n",
      "         2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,\n",
      "         2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,\n",
      "         2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,\n",
      "         2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,\n",
      "         2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,  2.0025e-03,\n",
      "         2.0025e-03,  2.0024e-03,  1.6419e-03,  3.4859e-04,  6.1919e-05,\n",
      "         1.4209e-05,  1.7533e-06, -3.0475e-06, -5.4717e-06, -6.9243e-06,\n",
      "        -7.8914e-06, -8.5776e-06, -9.0835e-06, -9.4651e-06, -9.7570e-06,\n",
      "        -9.9821e-06, -1.0157e-05, -1.0293e-05, -1.0399e-05, -1.0482e-05,\n",
      "        -1.0547e-05, -1.0598e-05, -1.0638e-05, -1.0669e-05, -1.0693e-05,\n",
      "        -1.0713e-05, -1.0728e-05, -1.0739e-05, -1.0749e-05, -1.0756e-05,\n",
      "        -1.0762e-05, -1.0766e-05, -1.0770e-05, -1.0772e-05, -1.0775e-05,\n",
      "        -1.0776e-05, -1.0778e-05, -1.0779e-05])\n",
      "torch.Size([128, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 16129 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m GCNModel(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, LR, epochs, val_loader)\u001b[0m\n\u001b[0;32m     22\u001b[0m batch\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36mGCNModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m#x = self.temporal(x, edge_index, edge_attr)  # Pass through temporal layer\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:176\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:61\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     57\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m     58\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[1;32m---> 61\u001b[0m     edge_index, tmp_edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m tmp_edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m tmp_edge_weight\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\utils\\loop.py:302\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    298\u001b[0m     loop_attr[edge_index[\u001b[38;5;241m0\u001b[39m][inv_mask]] \u001b[38;5;241m=\u001b[39m edge_attr[inv_mask]\n\u001b[0;32m    300\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_attr[mask], loop_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 302\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 16129 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize the model\n",
    "model = GCNModel(in_channels=2, hidden_channels=512, out_channels=6)\n",
    "train(train_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = loss_fn(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch in train_loader:\n",
    "            out = model(batch)\n",
    "            test_loss += F.mse_loss(out, batch.y).item() * batch.num_graphs\n",
    "        test_loss /= len(train_loader.dataset)\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4602a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data as GData, Batch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import interp1d\n",
    "import pickle\n",
    "import torch_geometric.transforms as T\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SCALER = MinMaxScaler()\n",
    "\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, signalFolder=\"D:/SamplingResults2\", sampleFile=\"newSamples.pkl\", runs=range(100), steps=128):\n",
    "        # Load both disp1 and disp2 from each folder\n",
    "        # Folders ordered according to index of sample\n",
    "        # Use the corresponding sample as y -> append probe?\n",
    "        self.data = []\n",
    "        self.output = []\n",
    "        self.input = []\n",
    "        \n",
    "        with open(f\"{sampleFile}\", \"rb\") as f:\n",
    "             samples = pickle.load(f)\n",
    "        \n",
    "        # Gather all the data first\n",
    "        inputs = []\n",
    "        for run in tqdm(runs):\n",
    "            inp = []\n",
    "            fail = False\n",
    "            \n",
    "            files = os.listdir(f\"{signalFolder}/{run}/\")\n",
    "            \n",
    "            if files != ['Disp1.csv', 'Disp2.csv']:\n",
    "                continue\n",
    "            \n",
    "            for file in files:\n",
    "                a = pd.read_csv(f\"{signalFolder}/{run}/{file}\")\n",
    "                a.rename(columns = {'0':'x', '0.1': 'y'}, inplace = True)\n",
    "                \n",
    "                if a['x'].max() != 7.0:\n",
    "                    fail = True\n",
    "                    break\n",
    "                \n",
    "                # Interpolate curve for consistent x values\n",
    "                xNew = np.linspace(0, 7, num=steps, endpoint=False)\n",
    "                interped = interp1d(a['x'], a['y'], kind='cubic', fill_value=\"extrapolate\")(xNew)\n",
    "                    \n",
    "                inp.append(interped.astype(\"float32\"))\n",
    "            \n",
    "            if not fail:\n",
    "                if len(inp) != 2:\n",
    "                    raise Exception(\"sdf\")\n",
    "\n",
    "                self.input.append(inp)\n",
    "\n",
    "                self.output.append(samples[int(run)])\n",
    "\n",
    "        # Scale input data\n",
    "        \n",
    "        SCALER.fit_transform(self.output)\n",
    "        self.output = SCALER.transform(self.output)\n",
    "        self.output = self.output.reshape(-1, 6)\n",
    "        self.output = torch.tensor(self.output, dtype=torch.float)\n",
    "        \n",
    "        # Add y values to data objects\n",
    "        for i, input_data in enumerate(self.input):\n",
    "            # Create node features tensor\n",
    "            x = torch.tensor(input_data, dtype=torch.float)\n",
    "\n",
    "            # Create edge_index tensor for the concatenated graph\n",
    "            num_nodes_1 = len(inp[0])\n",
    "            num_nodes_2 = len(inp[1])\n",
    "            edge_index_1 = torch.tensor([[i, j] for i in range(num_nodes_1 - 1) for j in range(num_nodes_1, num_nodes_1 + num_nodes_2 - 1)], dtype=torch.long)\n",
    "            edge_index_2 = torch.tensor([[j, i] for i, j in edge_index_1], dtype=torch.long)\n",
    "            edge_index = torch.cat([edge_index_1, edge_index_2], dim=-1)\n",
    "\n",
    "            # Set edge weights to 1 for all adjacent edges, and negative values for edges connecting nodes from different graphs\n",
    "            edge_weight = torch.ones(edge_index.shape[1])\n",
    "            edge_weight[num_nodes_1-1::num_nodes_1] = -1.\n",
    "            self.data.append(Data(x=x, edge_index=edge_index, edge_weight=edge_weight, y=self.output[i]))\n",
    "        print(self.data[0].x)    \n",
    "            \n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def custom_collate(batch):\n",
    "    print(batch)\n",
    "    \"\"\"\n",
    "    Collate function that can handle PyTorch Geometric Data objects.\n",
    "    \"\"\"\n",
    "    print(\"BATCH: \", Batch.from_data_list(batch))\n",
    "    return Batch.from_data_list(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e82ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered.pkl\", \"rb\") as f:\n",
    "    runs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f77af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

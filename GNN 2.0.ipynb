{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9978d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, Sequential, MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "import numpy as np\n",
    "from torch_geometric.data import Batch\n",
    "import torch\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "DEVICE = torch.device(\"cuda:0\" if not torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "acca299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contains non-linear activation function ReLu.\n",
    "    This likely wont be an effective approximation for the data.\n",
    "    You could experiment with sigmoid, or preferably,\n",
    "    you could try using a non-linear layer such as:\n",
    "        - a multi-layer perceptron (MLP)\n",
    "        - RNN with\n",
    "            - a gated recurrent unit (GRU)\n",
    "            - long short-term memory (LSTM) unit\n",
    "        - RNN layer can add significant performance see:\n",
    "            https://ieeexplore.ieee.org/document/9649108\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TemporalLayer, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Sort the edges by timestamp to ensure the correct temporal order\n",
    "        #edge_attr, perm = edge_attr.sort()\n",
    "        #edge_index = edge_index[:, perm]\n",
    "        #x = x[perm]\n",
    "\n",
    "        # Aggregate the temporal information for each node using the mean\n",
    "        node_attrs = torch.zeros(x.shape[0], edge_attr.shape[1], device=x.device)\n",
    "        node_attrs.index_add_(0, edge_index[1], edge_attr)\n",
    "        node_counts = torch.zeros(x.shape[0], edge_attr.shape[1], device=x.device)\n",
    "        node_counts.index_add_(0, edge_index[1], torch.ones_like(edge_attr))\n",
    "        node_attrs /= node_counts\n",
    "\n",
    "        # Pass the node attributes through a linear layer to get the temporal embeddings\n",
    "        x = F.relu(self.linear(node_attrs))\n",
    "\n",
    "        return x\n",
    "\n",
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(1, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.temporal = TemporalLayer(in_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "        print(edge_weight.shape, edge_index.shape, x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #x = self.temporal(x, edge_index, edge_attr)  # Pass through temporal layer\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b783ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, LR=0.1, epochs=2000, val_loader=None):\n",
    "    net.to(DEVICE)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "    criterion = nn.L1Loss()\n",
    "    all_MSE = nn.L1Loss()\n",
    "    val_losses = []\n",
    "    print(f\"Using: {DEVICE}\")\n",
    "                            \n",
    "    parameter_loss = []\n",
    "    losses = []\n",
    "    processed = 0\n",
    "    last_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        \n",
    "        net.train()\n",
    "        with tqdm(train_loader, unit=\"batch\") as it:\n",
    "            if epoch > 0:\n",
    "                it.set_postfix(lastLoss=last_loss, valLoss=val_losses[-1])\n",
    "            for idx, batch in enumerate(it):\n",
    "                it.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "                batch.to(DEVICE)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch)\n",
    "                loss = loss_fn(out, batch.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                for i in range(len(predicted)):\n",
    "                    current_MSE = []\n",
    "                    for j in range(6):\n",
    "                        current_MSE.append(all_MSE(out[i][j], predicted[i][j]).item())\n",
    "                    parameter_loss.append(current_MSE)\n",
    "                    processed += 1\n",
    "        \n",
    "        if val_loader:\n",
    "            val_loss = 0\n",
    "            net.eval()\n",
    "            for idx, data in enumerate(val_loader):\n",
    "                inp, out = data['input'].to(DEVICE), data['output'].to(DEVICE)\n",
    "\n",
    "                predicted = net(inp)\n",
    "                cost = criterion(out, predicted)\n",
    "                val_loss += cost.item()\n",
    "            val_loss /= len(val_loader)  \n",
    "            val_losses.append(val_loss)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        last_loss = loss/len(it)\n",
    "    print(\"Parameters: Skin YM, Adipose YM, Skin PR, Adipose PR, Skin Perm, Adipose Perm\")\n",
    "    print(f\"Sampled Ranges: 10e3 - 50e3, 1e3 - 25e3, 0.48 - 0.499, 0.48 - 0.499, 10e - 12-10e10, 10e-12 - 10e10\") \n",
    "    print(f\"Average parameter loss: {np.mean(np.reshape(np.array(parameter_loss), (-1, 6)), axis=0)}\")        \n",
    "    print(f\"Average overall loss: {np.sum(losses)/processed}\")\n",
    "    return losses, parameter_loss, val_losses\n",
    "\n",
    "def test(test_loader, net):\n",
    "    net.to(DEVICE)\n",
    "    net.eval()\n",
    "    criterion = nn.L1Loss()\n",
    "    crit = nn.L1Loss()\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "            loss = 0\n",
    "            with tqdm(test_loader, unit=\" batch\") as it:\n",
    "                for batch in enumerate(it):\n",
    "                    loss = loss_fn(out, batch.y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    predicted = net(inp) \n",
    "                    cost = criterion(out, predicted)\n",
    "                    l_t = cost.item()\n",
    "                    loss += l_t\n",
    "                    for i in range(len(predicted)):\n",
    "                        p = predicted[i].cpu().numpy().reshape(1, -1)\n",
    "                        o = out[i].cpu().numpy().reshape(1, -1)\n",
    "                        print(F\"Predicted: {SCALER.inverse_transform(p)}\")\n",
    "                        print(F\"Real: {SCALER.inverse_transform(o)}\")\n",
    "                        print(f\"Difference: {abs(p - o)}\\n\\n\")\n",
    "                    \n",
    "                    #print(f\"\\n\\n\\nBatch: {idx}\")\n",
    "                   # print(f\"loss: {l_t}\")\n",
    "                    #for i, target in enumerate(out):\n",
    "                   #     errs = []\n",
    "                   #     print(f\"Targer: {target}, \\npredicted: {predicted[i]}\\n\\n\")\n",
    "                   #     for j in range(len(predicted)):\n",
    "                   #         errs.append(abs(predicted[i]-target[i])**2)\n",
    "                   #     print(f\"MSE: {np.mean(errs[0])}\")\n",
    "            \n",
    "            print(f\"Average Loss: {loss/len(test_loader)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1c389159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16129])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[7].edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9032cf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 202.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the dataset\n",
    "dataset = SignalDataset(runs=runs[:10])\n",
    "\n",
    "train_n = int(0.8 * len(dataset))\n",
    "test_n = len(dataset) - train_n\n",
    "train_set, test_set = random_split(dataset, [train_n, test_n])\n",
    "train_loader, test_loader = DataLoader(train_set, batch_size=2, shuffle=True, collate_fn=custom_collate), \\\n",
    "                            DataLoader(test_set, batch_size=2, shuffle=True, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "297db007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000:   0%|                                                                           | 0/4 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8]) torch.Size([4, 32258]) torch.Size([4, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [32258] at index 0 does not match the shape of the indexed tensor [8] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [157]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m GCNModel(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, LR, epochs, val_loader)\u001b[0m\n\u001b[0;32m     22\u001b[0m batch\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [155]\u001b[0m, in \u001b[0;36mGCNModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_weight\u001b[38;5;241m.\u001b[39mshape, edge_index\u001b[38;5;241m.\u001b[39mshape, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#x = self.temporal(x, edge_index, edge_attr)  # Pass through temporal layer\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:176\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:61\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     57\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m     58\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[1;32m---> 61\u001b[0m     edge_index, tmp_edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m tmp_edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m tmp_edge_weight\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\utils\\loop.py:298\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill_value\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m     inv_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mmask\n\u001b[1;32m--> 298\u001b[0m     loop_attr[edge_index[\u001b[38;5;241m0\u001b[39m][inv_mask]] \u001b[38;5;241m=\u001b[39m \u001b[43medge_attr\u001b[49m\u001b[43m[\u001b[49m\u001b[43minv_mask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    300\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_attr[mask], loop_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    302\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index[:, mask], loop_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [32258] at index 0 does not match the shape of the indexed tensor [8] at index 0"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize the model\n",
    "model = GCNModel(in_channels=2, hidden_channels=512, out_channels=6)\n",
    "train(train_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = loss_fn(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch in train_loader:\n",
    "            out = model(batch)\n",
    "            test_loss += F.mse_loss(out, batch.y).item() * batch.num_graphs\n",
    "        test_loss /= len(train_loader.dataset)\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4602a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data as GData, Batch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import interp1d\n",
    "import pickle\n",
    "import torch_geometric.transforms as T\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SCALER = MinMaxScaler()\n",
    "\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, signalFolder=\"D:/SamplingResults2\", sampleFile=\"newSamples.pkl\", runs=range(100), steps=128):\n",
    "        # Load both disp1 and disp2 from each folder\n",
    "        # Folders ordered according to index of sample\n",
    "        # Use the corresponding sample as y -> append probe?\n",
    "        self.data = []\n",
    "        self.output = []\n",
    "        self.input = []\n",
    "        \n",
    "        with open(f\"{sampleFile}\", \"rb\") as f:\n",
    "             samples = pickle.load(f)\n",
    "        \n",
    "        # Gather all the data first\n",
    "        inputs = []\n",
    "        for run in tqdm(runs):\n",
    "            inp = []\n",
    "            fail = False\n",
    "            \n",
    "            files = os.listdir(f\"{signalFolder}/{run}/\")\n",
    "            \n",
    "            if files != ['Disp1.csv', 'Disp2.csv']:\n",
    "                continue\n",
    "            \n",
    "            for file in files:\n",
    "                a = pd.read_csv(f\"{signalFolder}/{run}/{file}\")\n",
    "                a.rename(columns = {'0':'x', '0.1': 'y'}, inplace = True)\n",
    "                \n",
    "                if a['x'].max() != 7.0:\n",
    "                    fail = True\n",
    "                    break\n",
    "                \n",
    "                # Interpolate curve for consistent x values\n",
    "                xNew = np.linspace(0, 7, num=steps, endpoint=False)\n",
    "                interped = interp1d(a['x'], a['y'], kind='cubic', fill_value=\"extrapolate\")(xNew)\n",
    "                    \n",
    "                inp.append(interped.astype(\"float32\"))\n",
    "            \n",
    "            if not fail:\n",
    "                if len(inp) != 2:\n",
    "                    raise Exception(\"sdf\")\n",
    "\n",
    "                self.input.append(inp)\n",
    "\n",
    "                self.output.append(samples[int(run)])\n",
    "\n",
    "        # Scale input data\n",
    "        \n",
    "        SCALER.fit_transform(self.output)\n",
    "        self.output = SCALER.transform(self.output)\n",
    "        self.output = self.output.reshape(-1, 6)\n",
    "        self.output = torch.tensor(self.output, dtype=torch.float)\n",
    "        \n",
    "        # Add y values to data objects\n",
    "        for i, input_data in enumerate(self.input):\n",
    "            # Create node features tensor\n",
    "            x = torch.tensor(input_data, dtype=torch.float)\n",
    "\n",
    "            # Create edge_index tensor for the concatenated graph\n",
    "            num_nodes_1 = len(inp[0])\n",
    "            num_nodes_2 = len(inp[1])\n",
    "            edge_index_1 = torch.tensor([[i, j] for i in range(num_nodes_1 - 1) for j in range(num_nodes_1, num_nodes_1 + num_nodes_2 - 1)], dtype=torch.long)\n",
    "            edge_index_2 = torch.tensor([[j, i] for i, j in edge_index_1], dtype=torch.long)\n",
    "            edge_index = torch.cat([edge_index_1, edge_index_2], dim=-1)\n",
    "\n",
    "            # Set edge weights to 1 for all adjacent edges, and negative values for edges connecting nodes from different graphs\n",
    "            edge_weight = torch.ones(edge_index.shape[1])\n",
    "            edge_weight[num_nodes_1-1::num_nodes_1] = -1.\n",
    "            self.data.append(Data(x=x, edge_index=edge_index.t().contiguous(), edge_weight=edge_weight, y=self.output[i]))        \n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    Collate function that can handle PyTorch Geometric Data objects.\n",
    "    \"\"\"\n",
    "    return Batch.from_data_list(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e82ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered.pkl\", \"rb\") as f:\n",
    "    runs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f77af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
